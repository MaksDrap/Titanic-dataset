{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65279d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading provided train set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "cwd= os.getcwd() \n",
    "path = os.path.join(cwd,'data')\n",
    "\n",
    "def get_train_set():\n",
    "    print ('loading provided train set.')\n",
    "    fp = os.path.join(path,'train_titanic.csv')\n",
    "    df_train = pd.read_csv(fp, encoding='ISO-8859-1',low_memory=False)\n",
    "    df_train['Sex'] = df_train['Sex'].map({'male': 1, 'female': 0})\n",
    "    df_train['Sex'] = df_train['Sex'].astype(int)\n",
    "    return df_train\n",
    "\n",
    "\n",
    "df_train= get_train_set ()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b2dbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading provided test set .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name  Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    1   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
       "3          895       3                              Wirz, Mr. Albert    1   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_set():    \n",
    "    print ('loading provided test set .')\n",
    "    fp = os.path.join(path,'test_titanic.csv')\n",
    "    df_test = pd.read_csv(fp, encoding='ISO-8859-1',low_memory=False)\n",
    "    \n",
    "    return df_test\n",
    "\n",
    "df_test= get_test_set()\n",
    "df_test['Sex'] = df_test['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "df_test['Sex'] = df_test['Sex'].astype(int)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec3f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing samples with missing survival information.\n",
      "Length before cleaning= 891\n",
      "Length after cleaning= 891\n"
     ]
    }
   ],
   "source": [
    "def remove_missing_survival_info(df):\n",
    "    print('Removing samples with missing survival information.')\n",
    "    print('Length before cleaning= {:,}'.format(len(df)))\n",
    "    df = df.dropna(subset=['Sex'])\n",
    "    print('Length after cleaning= {:,}'.format(len(df)))\n",
    "    return df\n",
    "\n",
    "df_train = remove_missing_survival_info(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c5bc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_X_train_test(df_train, df_test): \n",
    "    print('Extracting features.')\n",
    "    df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1\n",
    "    df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
    "    cols_to_keep = [\n",
    "        'Pclass',\n",
    "        'Sex',\n",
    "        'Age',\n",
    "        'FamilySize'\n",
    "    ]\n",
    "\n",
    "    X_train = df_train[cols_to_keep]\n",
    "    X_test = df_test[cols_to_keep]\n",
    "    return X_train, X_test, cols_to_keep\n",
    "\n",
    "\n",
    "X_train, X_test, features  = get_X_train_test(df_train, df_test)\n",
    "\n",
    "y_train = df_train['Survived']\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d964c54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "   Pclass  Sex   Age  FamilySize\n",
      "0       3    1  22.0           2\n",
      "1       1    0  38.0           2\n",
      "2       3    0  26.0           1\n",
      "3       1    0  35.0           2\n",
      "4       3    1  35.0           1\n",
      "\n",
      "X_test:\n",
      "   Pclass  Sex   Age  FamilySize\n",
      "0       3    1  34.5           1\n",
      "1       3    0  47.0           2\n",
      "2       2    1  62.0           1\n",
      "3       3    1  27.0           1\n",
      "4       3    0  22.0           3\n",
      "\n",
      "Features:\n",
      "['Pclass', 'Sex', 'Age', 'FamilySize']\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test.head())\n",
    "\n",
    "print(\"\\nFeatures:\")\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043aba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass          int64\n",
      "Sex             int32\n",
      "Age           float64\n",
      "FamilySize      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e92196e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass          int64\n",
       "Sex             int32\n",
       "Age           float64\n",
       "FamilySize      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encoder(X_train,X_test):    \n",
    "    print ('label encoding.')\n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy() \n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        le = LabelEncoder().fit(X_train[col].astype(str)) \n",
    "        X_train[col] = le.transform(X_train[col].astype(str))\n",
    "        X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    return X_train,X_test\n",
    "\n",
    "X_train,X_test= label_encoder(X_train,X_test)\n",
    "X_train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b4a836a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        False\n",
       "Sex           False\n",
       "Age            True\n",
       "FamilySize    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a16f0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling NaN...\n",
      "filling NaN...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_na(df):\n",
    "    print ('filling NaN...')\n",
    "    for col in list(df):\n",
    "        if df[col].isna().any():\n",
    "            df[col]= df[col].fillna(0)\n",
    "\n",
    "fill_na(X_train)\n",
    "fill_na(X_test) \n",
    "X_train.isna().any().any(), X_test.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e973e9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        False\n",
       "Sex           False\n",
       "Age           False\n",
       "FamilySize    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2038fea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalize(X_train, X_test):\n",
    "    print ('normalizing.')\n",
    "    scaler= MinMaxScaler()\n",
    "    X_train_scaled= scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled \n",
    "\n",
    "X_train_scaled, X_test_scaled  = normalize(X_train, X_test)\n",
    "type(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a2b391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing.\n",
      "\n",
      "LogisticRegression.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'C': 0.1}\n",
      "Grid best score (f1):  0.7092684925689026\n",
      "test f1= 0.7272727272727273\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'max_depth': 50}\n",
      "Grid best score (f1):  0.7497965890496477\n",
      "test f1= 0.8828828828828829\n",
      "\n",
      "RandomForestClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'n_estimators': 20}\n",
      "Grid best score (f1):  0.7486465126884179\n",
      "test f1= 0.8695652173913044\n",
      "\n",
      "SVC\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'C': 0.01}\n",
      "Grid best score (f1):  0.6261557023715565\n",
      "test f1= 0.7241379310344828\n",
      "\n",
      "NB\n",
      "train set f1= 0.7325227963525835\n",
      "train set f1= 0.6935483870967741\n",
      "\n",
      "GradientBoostingClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'max_depth': 5}\n",
      "Grid best score (f1):  0.7664158686540038\n",
      "test f1= 0.8672566371681415\n",
      "\n",
      "MLP.\n",
      "Running GridSearchCV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max f1 ):  {'alpha': 0.1}\n",
      "Grid best score (f1):  0.7303046283309959\n",
      "test f1= 0.7207207207207208\n",
      "\n",
      "XGB.\n",
      "f1_score  = 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "X_train_scaled, X_test_scaled = normalize(X_train, X_test)\n",
    "\n",
    "\n",
    "y_test = y_train[:len(y_train)//5] \n",
    "\n",
    "X_test_scaled = X_train_scaled[:len(y_train)//5, :]\n",
    "\n",
    "def run_GridSearchCV(clf,grid_values, X_train_scaled, X_test_scaled, y_train, y_test= None):\n",
    "    print ('Running GridSearchCV.')\n",
    "    grid_clf = GridSearchCV(clf, param_grid=grid_values,scoring='f1')\n",
    "    grid_clf.fit(X_train_scaled, y_train)\n",
    "    print('Grid best parameter (max f1 ): ', grid_clf.best_params_) \n",
    "    print('Grid best score (f1): ', grid_clf.best_score_) \n",
    "\n",
    "    if not y_test is None:\n",
    "        test_score= grid_clf.score(X_test_scaled, y_test)\n",
    "        print(\"test f1= {}\".format(test_score))\n",
    "        \n",
    "def run_all_classifiers(X_train_scaled, X_test_scaled, y_train, y_test=None, list_classifiers=None):\n",
    "    if list_classifiers is None or 'LogisticRegression' in list_classifiers:\n",
    "        print('\\nLogisticRegression.')\n",
    "        clf = LogisticRegression(max_iter=10000)\n",
    "        grid_values = {'C': [0.005, 0.01, 0.1, 1, 100, 10000, 100000]}\n",
    "        run_GridSearchCV(clf, grid_values, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "    if list_classifiers is None or 'DecisionTreeClassifier' in list_classifiers:\n",
    "        print('\\nDecisionTreeClassifier')\n",
    "        clf = DecisionTreeClassifier()       \n",
    "        grid_values = {'max_depth': [2, 5, 7, 20, 50]}\n",
    "        run_GridSearchCV(clf, grid_values, X_train_scaled, X_test_scaled, y_train, y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'RandomForestClassifier' in list_classifiers:\n",
    "        print('\\nRandomForestClassifier.')\n",
    "        clf = RandomForestClassifier()       \n",
    "        grid_values = {'n_estimators': [20, 50]}  \n",
    "        run_GridSearchCV(clf, grid_values, X_train_scaled, X_test_scaled, y_train, y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'SVC' in list_classifiers:\n",
    "        print('\\nSVC')\n",
    "        clf = SVC()  \n",
    "        grid_values = {'C': [0.005, 0.01]}  \n",
    "        run_GridSearchCV(clf, grid_values, X_train_scaled, X_test_scaled, y_train, y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'NB' in list_classifiers:\n",
    "        print('\\nNB')\n",
    "        clf = GaussianNB().fit(X_train_scaled, y_train)\n",
    "        train_f1 = f1_score(y_train, clf.predict(X_train_scaled))\n",
    "        print(\"train set f1= {}\".format(train_f1))\n",
    "        if not y_test is None:\n",
    "            test_f1 = f1_score(y_test, clf.predict(X_test_scaled))\n",
    "            print(\"train set f1= {}\".format(test_f1))\n",
    "\n",
    "    if list_classifiers is None or 'GradientBoostingClassifier' in list_classifiers:\n",
    "        print('\\nGradientBoostingClassifier.')\n",
    "        clf = GradientBoostingClassifier()         \n",
    "        grid_values = {'max_depth': [3, 5, 7]}\n",
    "        run_GridSearchCV(clf, grid_values, X_train_scaled, X_test_scaled, y_train, y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'MLP' in list_classifiers:\n",
    "        print('\\nMLP.')\n",
    "        clf = MLPClassifier(hidden_layer_sizes=[50])  \n",
    "        grid_values = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "        run_GridSearchCV(clf, grid_values, X_train_scaled, X_test_scaled, y_train, y_test)   \n",
    "\n",
    "    if list_classifiers is None or 'XGB' in list_classifiers:\n",
    "        print('\\nXGB.')\n",
    "        clf = XGBClassifier().fit(X_train_scaled, y_train)\n",
    "        y_predicted = clf.predict(X_test_scaled)\n",
    "        print('f1_score  = {:.2}'.format(f1_score(y_test, y_predicted)))\n",
    "\n",
    "# Usage\n",
    "list_classifiers = ['RandomForestClassifier', 'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'NB', 'GradientBoostingClassifier', 'XGB']\n",
    "run_all_classifiers(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed3d8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(df_train, df_test):\n",
    "\n",
    "    df_train = remove_missing_survival_info(df_train)\n",
    "    y_train = df_train['Survived']\n",
    "\n",
    "    if 'Survived' in list(df_test):\n",
    "        df_test = remove_missing_survival_info(df_test)\n",
    "        y_test = df_test['Survived']\n",
    "    else:\n",
    "        y_test = None \n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_test, features = get_X_train_test(df_train, df_test)\n",
    "\n",
    "    X_train, X_test = label_encoder(X_train, X_test)\n",
    "\n",
    "    fill_na(X_train)\n",
    "    fill_na(X_test)\n",
    "\n",
    "    X_train_scaled, X_test_scaled = normalize(X_train, X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8092e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading provided train set.\n",
      "Removing samples with missing survival information.\n",
      "Length before cleaning= 668\n",
      "Length after cleaning= 668\n",
      "Removing samples with missing survival information.\n",
      "Length before cleaning= 223\n",
      "Length after cleaning= 223\n",
      "Extracting features.\n",
      "label encoding.\n",
      "filling NaN...\n",
      "filling NaN...\n",
      "normalizing.\n",
      "X_train_scaled shape= (668, 4)\n",
      "X_test_scaled shape= (223, 4)\n",
      "y_train set shape= (668,)\n",
      "y_test set shape= (223,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = get_train_set()\n",
    "df_train, df_test = train_test_split(df, random_state=0)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, features = apply_preprocessing(df_train, df_test)\n",
    "\n",
    "print('X_train_scaled shape= {}\\nX_test_scaled shape= {}'.format(X_train_scaled.shape, X_test_scaled.shape))\n",
    "print('y_train set shape= {}\\ny_test set shape= {}'.format(y_train.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be93301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'C': 0.1}\n",
      "Grid best score (f1):  0.7109181282099429\n",
      "test f1= 0.7065868263473053\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'max_depth': 5}\n",
      "Grid best score (f1):  0.7122180584184633\n",
      "test f1= 0.6878980891719746\n",
      "\n",
      "RandomForestClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'n_estimators': 10}\n",
      "Grid best score (f1):  0.7486218516955113\n",
      "test f1= 0.710843373493976\n",
      "\n",
      "NB\n",
      "Naive Bayes (NB):\n",
      "Train F1 Score: 0.7306122448979592\n",
      "\n",
      "\n",
      "\n",
      "GradientBoostingClassifier.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'max_depth': 3}\n",
      "Grid best score (f1):  0.7508988747762366\n",
      "test f1= 0.7547169811320756\n",
      "\n",
      "MLP.\n",
      "Running GridSearchCV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maks\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max f1 ):  {'alpha': 0.01}\n",
      "Grid best score (f1):  0.7266009922156101\n",
      "test f1= 0.7058823529411765\n",
      "\n",
      "xgboost.\n",
      "Running GridSearchCV.\n",
      "Grid best parameter (max f1 ):  {'n_estimators': 150}\n",
      "Grid best score (f1):  0.7308338790341553\n",
      "test f1= 0.7349397590361447\n"
     ]
    }
   ],
   "source": [
    "def run_all_classifiers(X_train, X_test, y_train, y_test, list_classifiers):\n",
    "    for classifier_name in list_classifiers:\n",
    "        if classifier_name == 'LogisticRegression':\n",
    "            print ('\\nLogisticRegression.')\n",
    "            clf = LogisticRegression()\n",
    "            grid_values = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\n",
    "            run_GridSearchCV(clf, grid_values, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        elif classifier_name == 'DecisionTreeClassifier':\n",
    "            print ('\\nDecisionTreeClassifier')\n",
    "            clf = DecisionTreeClassifier()\n",
    "            grid_values = {'max_depth': [5, 10, 15, 20, 25, 30]}\n",
    "            run_GridSearchCV(clf, grid_values, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        elif classifier_name == 'RandomForestClassifier':\n",
    "            print ('\\nRandomForestClassifier.')\n",
    "            clf = RandomForestClassifier()\n",
    "            grid_values = {'n_estimators': [10, 20, 30, 40, 50]}\n",
    "            run_GridSearchCV(clf, grid_values, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        elif classifier_name == 'NB':\n",
    "            print ('\\nNB')\n",
    "            clf = GaussianNB()\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_train)\n",
    "            train_score = f1_score(y_train, y_pred)\n",
    "            print(\"Naive Bayes (NB):\")\n",
    "            print(\"Train F1 Score:\", train_score)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif classifier_name == 'GradientBoostingClassifier':\n",
    "            print ('\\nGradientBoostingClassifier.')\n",
    "            clf = GradientBoostingClassifier()\n",
    "            grid_values = {'max_depth': [3, 5, 7, 9, 11]}\n",
    "            run_GridSearchCV(clf, grid_values, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        elif classifier_name == 'MLP':\n",
    "            print ('\\nMLP.')\n",
    "            clf = MLPClassifier()\n",
    "            grid_values = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "            run_GridSearchCV(clf, grid_values, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        elif classifier_name == 'xgboost':\n",
    "            print ('\\nxgboost.')\n",
    "            clf = XGBClassifier()\n",
    "            grid_values = {'n_estimators': [50, 100, 150, 200, 250]}\n",
    "            run_GridSearchCV(clf, grid_values, X_train, X_test, y_train, y_test)\n",
    "\n",
    "list_classifiers = [\n",
    "    'LogisticRegression',\n",
    "    'DecisionTreeClassifier',\n",
    "    'RandomForestClassifier',\n",
    "    'NB',\n",
    "    'GradientBoostingClassifier',\n",
    "    'MLP',\n",
    "    'xgboost',\n",
    "]\n",
    "\n",
    "run_all_classifiers(X_train_scaled, X_test_scaled, y_train, y_test, list_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc31a36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 scores on the whole set: [0.70707071 0.75925926 0.75       0.71578947 0.77083333]\n",
      "Mean of predictions: 0.3632286995515695\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = {'max_depth': 7}\n",
    "\n",
    "clf = GradientBoostingClassifier(**best_params)\n",
    "\n",
    "f1_train = cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "print(\"Cross-validated F1 scores on the whole set:\", f1_train)\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Mean of predictions:\", np.mean(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b004f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
